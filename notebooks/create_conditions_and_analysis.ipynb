{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb728c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def select_epochs_by_annotations(\n",
    "    epochs: mne.Epochs,\n",
    "    descriptors: List[str],\n",
    "    reject_log: Optional[np.ndarray] = None,  # (n_epochs, n_channels) with {0,1,2} or NaN\n",
    "    *,\n",
    "    min_overlap: float = 0.5,\n",
    "    fallback_duration_s: float = 1.0,\n",
    "    allow_interpolated: bool = True,\n",
    "    max_interp_frac: float = 0.3,\n",
    "    max_bad_chns: int = 3,\n",
    "    min_run: int = 1,\n",
    "    case_sensitive: bool = False,\n",
    "    return_indices: bool = False,\n",
    ") -> Dict[str, Union[np.ndarray, mne.Epochs]]:\n",
    "    \"\"\"\n",
    "    Epochs-only selection using epochs.annotations for interval overlap + a per-epoch\n",
    "    quality filter from reject_log. Any NaN in reject_log is treated as GOOD (0).\n",
    "    \"\"\"\n",
    "    n_epochs = len(epochs)\n",
    "    if n_epochs == 0:\n",
    "        empty = np.array([], dtype=int) if return_indices else epochs[:0]\n",
    "        return {d: empty for d in descriptors}\n",
    "\n",
    "    sf = float(epochs.info[\"sfreq\"])\n",
    "\n",
    "    # ---------- 1) Usable-epoch mask from reject_log (NaN -> good) ----------\n",
    "    usable = np.ones(n_epochs, dtype=bool)\n",
    "    if reject_log is not None:\n",
    "        if reject_log.ndim != 2 or reject_log.shape[0] != n_epochs:\n",
    "            raise ValueError(\"reject_log must be (n_epochs, n_channels) with values {0,1,2} or NaN.\")\n",
    "        # Treat NaN as good (0)\n",
    "        rlog = np.nan_to_num(reject_log.astype(float), nan=0.0)\n",
    "        n_ch = rlog.shape[1]\n",
    "        bad_counts = (rlog == 1.0).sum(axis=1)\n",
    "        interp_frac = (rlog == 2.0).sum(axis=1) / n_ch\n",
    "        usable &= bad_counts <= int(max_bad_chns)\n",
    "        if allow_interpolated:\n",
    "            usable &= interp_frac <= float(max_interp_frac)\n",
    "        else:\n",
    "            usable &= (rlog == 2.0).sum(axis=1) == 0\n",
    "\n",
    "    # ---------- 2) Build & merge annotation intervals per descriptor ----------\n",
    "    queries = [d if case_sensitive else str(d).lower() for d in descriptors]\n",
    "    buckets = {d: [] for d in descriptors}\n",
    "\n",
    "    def _merge(iv):\n",
    "        if not iv:\n",
    "            return []\n",
    "        iv = sorted(iv)\n",
    "        out = [list(iv[0])]\n",
    "        for s, e in iv[1:]:\n",
    "            if s <= out[-1][1]:\n",
    "                out[-1][1] = max(out[-1][1], e)\n",
    "            else:\n",
    "                out.append([s, e])\n",
    "        return [(s, e) for s, e in out]\n",
    "\n",
    "    if epochs.annotations is not None and len(epochs.annotations) > 0:\n",
    "        for ann in epochs.annotations:\n",
    "            desc = ann[\"description\"] or \"\"\n",
    "            if not case_sensitive:\n",
    "                desc = desc.lower()\n",
    "            onset_s = float(ann[\"onset\"])\n",
    "            dur_s = float(ann[\"duration\"]) or 0.0\n",
    "            if dur_s <= 0:\n",
    "                dur_s = float(fallback_duration_s)\n",
    "            s = int(round(onset_s * sf))\n",
    "            e = int(round((onset_s + dur_s) * sf))\n",
    "            if e <= s:\n",
    "                e = s + 1\n",
    "            for q, key in zip(queries, descriptors):\n",
    "                if q in desc:\n",
    "                    buckets[key].append((s, e))\n",
    "\n",
    "    for k in buckets:\n",
    "        buckets[k] = _merge(buckets[k])\n",
    "\n",
    "    # ---------- 3) Epoch bounds (absolute samples) ----------\n",
    "    ev = epochs.events[:, 0].astype(int)\n",
    "    ep_s = ev + int(round(epochs.tmin * sf))\n",
    "    ep_e = ev + int(round(epochs.tmax * sf))  # exclusive\n",
    "    ep_len = (ep_e - ep_s).astype(int)\n",
    "    need = np.maximum(0, (min_overlap * ep_len).astype(int))\n",
    "\n",
    "    # ---------- 4) Overlap test ----------\n",
    "    out_idxs = {k: [] for k in descriptors}\n",
    "    for i, (s0, e0) in enumerate(zip(ep_s, ep_e)):\n",
    "        if not usable[i] or e0 <= s0:\n",
    "            continue\n",
    "        req = int(need[i])\n",
    "        for name, ivs in buckets.items():\n",
    "            hit = any((min(e0, e1) - max(s0, s1)) >= req for (s1, e1) in ivs)\n",
    "            if hit:\n",
    "                out_idxs[name].append(i)\n",
    "\n",
    "    # ---------- 5) Consecutive run filter ----------\n",
    "    def _keep_runs(idxs: List[int], kmin: int) -> List[int]:\n",
    "        if kmin <= 1 or not idxs:\n",
    "            return idxs\n",
    "        idxs = np.array(sorted(set(idxs)), dtype=int)\n",
    "        cuts = np.where(np.diff(idxs) != 1)[0] + 1\n",
    "        starts = np.r_[0, cuts]\n",
    "        ends = np.r_[cuts, len(idxs)]\n",
    "        keep = []\n",
    "        for a, b in zip(starts, ends):\n",
    "            run = idxs[a:b]\n",
    "            if len(run) >= kmin:\n",
    "                keep.extend(run.tolist())\n",
    "        return keep\n",
    "\n",
    "    if min_run > 1:\n",
    "        for k in out_idxs:\n",
    "            out_idxs[k] = _keep_runs(out_idxs[k], int(min_run))\n",
    "\n",
    "    # ---------- 6) Return ----------\n",
    "    if return_indices:\n",
    "        return {k: np.asarray(v, dtype=int) for k, v in out_idxs.items()}\n",
    "    else:\n",
    "        return {k: epochs[v] for k, v in out_idxs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ef3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "from mushroom_hyperscanning.data import load_eeg\n",
    "\n",
    "SUBJECT = \"01\"\n",
    "CEREMONY = \"ceremony1\"\n",
    "BIDS_ROOT = \"../data/004_autoreject\"\n",
    "\n",
    "raw = load_eeg(SUBJECT, CEREMONY, root=BIDS_ROOT, preload=True)\n",
    "# raw.crop(tmax=60 * 20)  # use 20 minutes of data to test\n",
    "\n",
    "# Apply a band-pass filter to EEG (e.g. 0.3–45 Hz)\n",
    "raw.filter(l_freq=1, h_freq=60, picks=\"eeg\", phase=\"zero\")\n",
    "\n",
    "# Optionally also remove line noise (60 Hz harmonics for Québec/Canada)\n",
    "raw.notch_filter(freqs=[60], picks=\"eeg\", phase=\"zero\")\n",
    "\n",
    "p = Path(raw.filenames[0]).resolve()\n",
    "epochs_path = p.parent / str(p.name).replace(\"eeg\", \"epochs\")\n",
    "epochs = mne.read_epochs(epochs_path, preload=True)\n",
    "\n",
    "rejectlog_path = p.parent / str(p.name).replace(\"eeg.fif\", \"rejectlog.npy\")\n",
    "rejectlog = np.load(rejectlog_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e40479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = \"eyes closed\"\n",
    "var2 = \"eyes open\"\n",
    "# Descriptors to look for inside annotation descriptions (substring match)\n",
    "desc_list = [var1, var2]\n",
    "\n",
    "selected = select_epochs_by_annotations(\n",
    "    epochs=epochs,\n",
    "    descriptors=desc_list,\n",
    "    reject_log=rejectlog,\n",
    ")\n",
    "\n",
    "epochs_1 = selected[var1]\n",
    "epochs_2 = selected[var2]\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0dd8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Inputs: epochs_1 (control) and epochs_2 (song) must already exist\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# Config\n",
    "FMIN_ALL, FMAX_ALL = 1.0, 45.0\n",
    "N_JOBS = 1  # set >1 if you want\n",
    "BANDS = {\n",
    "    \"delta (1–4 Hz)\": (1.0, 4.0),\n",
    "    \"theta (4–8 Hz)\": (4.0, 8.0),\n",
    "    \"alpha (8–13 Hz)\": (8.0, 13.0),\n",
    "    \"beta (13–30 Hz)\": (13.0, 30.0),\n",
    "    \"gamma (30–45 Hz)\": (30.0, 45.0),\n",
    "}\n",
    "\n",
    "# Ensure a montage (does nothing if already set)\n",
    "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "for ep in (epochs_1, epochs_2):\n",
    "    try:\n",
    "        ep.set_montage(montage, match_case=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Make both Epochs have the same EEG channels in the same order\n",
    "# ---------------------------------------------------------------------\n",
    "ep1_eeg = epochs_1.copy().pick(picks=\"eeg\")\n",
    "ep2_eeg = epochs_2.copy().pick(picks=\"eeg\")\n",
    "\n",
    "common_eeg = [ch for ch in ep1_eeg.ch_names if ch in set(ep2_eeg.ch_names)]\n",
    "if not common_eeg:\n",
    "    raise ValueError(\"No common EEG channels between the two Epochs.\")\n",
    "epochs_1 = ep1_eeg.copy().pick(picks=common_eeg)\n",
    "epochs_2 = ep2_eeg.copy().pick(picks=common_eeg)\n",
    "\n",
    "conds = {\"cond1\": epochs_1, \"cond2\": epochs_2}\n",
    "cond_order = list(conds.keys())  # contrast will be cond_order[1] - cond_order[0] (relative %)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# PSD (Welch) once per condition on 1–45 Hz, in µV^2/Hz\n",
    "# ---------------------------------------------------------------------\n",
    "psd_data = {}  # cond -> (psds_uV2_perHz, freqs, info)\n",
    "for name, ep in conds.items():\n",
    "    psd = ep.compute_psd(method=\"welch\", fmin=FMIN_ALL, fmax=FMAX_ALL, n_overlap=0, n_jobs=N_JOBS)\n",
    "    P, f = psd.get_data(return_freqs=True)  # (n_epochs, n_ch, n_f), (n_f,)\n",
    "    P = P * 1e12  # V^2/Hz -> µV^2/Hz\n",
    "    psd_data[name] = (P, f, ep.info)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Relative band power (band / total 1–45 Hz) in percent\n",
    "# ---------------------------------------------------------------------\n",
    "rel_maps = {b: {} for b in BANDS}  # band -> cond -> (n_ch,)\n",
    "rel_vlims = {}  # band -> (vmin, vmax)\n",
    "\n",
    "for band_name, (fmin, fmax) in BANDS.items():\n",
    "    all_vals = []\n",
    "    for name, (P, f, info) in psd_data.items():\n",
    "        fi = np.where((f >= fmin) & (f <= fmax))[0]\n",
    "        if fi.size < 2:\n",
    "            raise RuntimeError(f\"Insufficient frequency bins for {band_name}\")\n",
    "\n",
    "        band_power = np.trapz(P[:, :, fi], f[fi], axis=2).mean(axis=0)  # µV^2, per ch\n",
    "        total_power = np.trapz(P, f, axis=2).mean(axis=0) + np.finfo(float).eps\n",
    "        rel_pct = 100.0 * (band_power / total_power)  # %\n",
    "        rel_maps[band_name][name] = rel_pct\n",
    "        all_vals.append(rel_pct)\n",
    "\n",
    "    all_vals = np.concatenate(all_vals)\n",
    "    vmin = float(np.percentile(all_vals, 5))\n",
    "    vmax = float(np.percentile(all_vals, 95))\n",
    "    if vmin == vmax:\n",
    "        vmax = vmin + 1e-6\n",
    "    rel_vlims[band_name] = (vmin, vmax)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Contrast (relative change): (cond2 - cond1) / cond1 * 100 (%)\n",
    "# ---------------------------------------------------------------------\n",
    "contrast_maps = {}  # band -> (n_ch,)\n",
    "for band_name in BANDS.keys():\n",
    "    b = rel_maps[band_name]\n",
    "    if len(cond_order) >= 2:\n",
    "        baseline = b[cond_order[0]]\n",
    "        contrast_maps[band_name] = 100.0 * ((b[cond_order[1]] - baseline) / (baseline + np.finfo(float).eps))\n",
    "    else:\n",
    "        contrast_maps[band_name] = np.zeros_like(next(iter(b.values())))\n",
    "\n",
    "# Symmetric limits per band for contrast (robust)\n",
    "contrast_vlims = {}\n",
    "for band_name, vals in contrast_maps.items():\n",
    "    a5, a95 = np.percentile(vals, [5, 95])\n",
    "    m = float(max(abs(a5), abs(a95)))\n",
    "    contrast_vlims[band_name] = (-m, m) if m > 0 else (-1e-6, 1e-6)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Plot: rows = [control (rel %), song (rel %), contrast (relative % change)]\n",
    "# ---------------------------------------------------------------------\n",
    "n_rows = 3 if len(conds) >= 2 else len(conds)\n",
    "fig, axes = plt.subplots(n_rows, len(BANDS), figsize=(4 * len(BANDS), 3.6 * n_rows), squeeze=False)\n",
    "\n",
    "# Condition rows (relative %)\n",
    "for r, cname in enumerate(cond_order):\n",
    "    info = psd_data[cname][2]\n",
    "    for c, (band_name, _) in enumerate(BANDS.items()):\n",
    "        data = rel_maps[band_name][cname]\n",
    "        vmin, vmax = rel_vlims[band_name]\n",
    "        ax = axes[r, c]\n",
    "        im, _ = mne.viz.plot_topomap(data, info, axes=ax, show=False, contours=0, cmap=\"viridis\", vlim=(vmin, vmax))\n",
    "        if r == 0:\n",
    "            ax.set_title(band_name, fontsize=11)\n",
    "        ax.set_xlabel(f\"{cname} (rel. %)\", fontsize=9)\n",
    "        cb = plt.colorbar(im, ax=ax, shrink=0.7)\n",
    "        cb.set_label(\"Relative power (%)\", rotation=90, fontsize=9)\n",
    "\n",
    "# Contrast row (relative % change)\n",
    "if len(conds) >= 2:\n",
    "    info = psd_data[cond_order[0]][2]  # same channel layout/order\n",
    "    r = 2\n",
    "    for c, (band_name, _) in enumerate(BANDS.items()):\n",
    "        data = contrast_maps[band_name]\n",
    "        vmin, vmax = contrast_vlims[band_name]\n",
    "        ax = axes[r, c]\n",
    "        im, _ = mne.viz.plot_topomap(data, info, axes=ax, show=False, contours=0, cmap=\"RdBu_r\", vlim=(vmin, vmax))\n",
    "        ax.set_xlabel(f\"{cond_order[1]} vs {cond_order[0]} (rel. %)\", fontsize=9)\n",
    "        cb = plt.colorbar(im, ax=ax, shrink=0.7)\n",
    "        cb.set_label(\"Δ relative power (%)\", rotation=90, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ca0b36",
   "metadata": {},
   "source": [
    "## Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d69f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne_bids import BIDSPath\n",
    "\n",
    "BIDS_ROOT = \"../data/004_autoreject_15min\"\n",
    "CEREMONY = \"ceremony1\"\n",
    "\n",
    "\n",
    "def get_epochs(subject, ceremony, condition, root):\n",
    "    paths = BIDSPath(subject=subject, session=ceremony, task=\"psilo\", datatype=\"eeg\", root=root).match()\n",
    "    paths = [p.fpath for p in paths if \"eeg\" in p.fpath.name]\n",
    "    assert len(paths) == 1, f\"Didn't get one path, got {len(paths)}\"\n",
    "\n",
    "    p = paths[0].resolve()\n",
    "    epochs_path = p.parent / str(p.name).replace(\"eeg\", \"epochs\")\n",
    "    epochs = mne.read_epochs(epochs_path, preload=True)\n",
    "\n",
    "    rejectlog_path = p.parent / str(p.name).replace(\"eeg.fif\", \"rejectlog.npy\")\n",
    "    rejectlog = np.load(rejectlog_path)\n",
    "\n",
    "    selected = select_epochs_by_annotations(\n",
    "        epochs=epochs,\n",
    "        descriptors=[condition],\n",
    "        reject_log=rejectlog,\n",
    "    )\n",
    "    return selected[condition]\n",
    "\n",
    "\n",
    "# subject 1\n",
    "epo1_cond1 = get_epochs(\"01\", CEREMONY, \"eyes open\", BIDS_ROOT)\n",
    "epo1_cond2 = get_epochs(\"01\", CEREMONY, \"eyes closed\", BIDS_ROOT)\n",
    "\n",
    "# subject 4\n",
    "epo2_cond1 = get_epochs(\"03\", CEREMONY, \"eyes open\", BIDS_ROOT)\n",
    "epo2_cond2 = get_epochs(\"03\", CEREMONY, \"eyes closed\", BIDS_ROOT)\n",
    "\n",
    "epo1_cond1, epo1_cond2, epo2_cond1, epo2_cond2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a176f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_epochs_by_index(epo1_cond1, epo1_cond2, epo2_cond1, epo2_cond2):\n",
    "    \"\"\"\n",
    "    Find common epoch indices across all conditions and participants\n",
    "    \"\"\"\n",
    "    # Get event IDs for each condition/participant\n",
    "    events1_cond1 = set(epo1_cond1.events[:, 2])\n",
    "    events1_cond2 = set(epo1_cond2.events[:, 2])\n",
    "    events2_cond1 = set(epo2_cond1.events[:, 2])\n",
    "    events2_cond2 = set(epo2_cond2.events[:, 2])\n",
    "\n",
    "    # Find common indices across all\n",
    "    common_indices = events1_cond1.intersection(events1_cond2, events2_cond1, events2_cond2)\n",
    "\n",
    "    return list(common_indices)\n",
    "\n",
    "\n",
    "# Step 2: Extract epochs with matching indices\n",
    "common_indices = match_epochs_by_index(epo1_cond1, epo1_cond2, epo2_cond1, epo2_cond2)\n",
    "\n",
    "# Select epochs with matching indices for each condition\n",
    "epo1_cond1_matched = epo1_cond1[np.isin(epo1_cond1.events[:, 2], common_indices)]\n",
    "epo1_cond2_matched = epo1_cond2[np.isin(epo1_cond2.events[:, 2], common_indices)]\n",
    "epo2_cond1_matched = epo2_cond1[np.isin(epo2_cond1.events[:, 2], common_indices)]\n",
    "epo2_cond2_matched = epo2_cond2[np.isin(epo2_cond2.events[:, 2], common_indices)]\n",
    "\n",
    "# Step 3: Equalize epoch counts (as shown in tutorial)\n",
    "mne.epochs.equalize_epoch_counts([epo1_cond1_matched, epo2_cond1_matched])\n",
    "mne.epochs.equalize_epoch_counts([epo1_cond2_matched, epo2_cond2_matched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a71ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from hypyp import analyses, stats, viz\n",
    "\n",
    "# --- 1) Helpers ---------------------------------------------------------------\n",
    "\n",
    "\n",
    "def align_epochs_for_hypyp(epo_a: mne.Epochs, epo_b: mne.Epochs, drop_bads=True):\n",
    "    \"\"\"Make two Epochs objects shape-compatible: same channels (order), same n_epochs.\"\"\"\n",
    "    # 1) keep only common EEG channels and enforce identical ordering\n",
    "    common = [ch for ch in epo_a.ch_names if ch in epo_b.ch_names]\n",
    "    if not common:\n",
    "        raise RuntimeError(\"No common channels between the two Epochs.\")\n",
    "    a = epo_a.copy().pick_channels(common, ordered=True)\n",
    "    b = epo_b.copy().pick_channels(common, ordered=True)\n",
    "\n",
    "    # 2) drop union of bads (optional)\n",
    "    if drop_bads:\n",
    "        bads = list(set(a.info.get(\"bads\", [])) | set(b.info.get(\"bads\", [])))\n",
    "        if bads:\n",
    "            a.drop_channels(bads, on_missing=\"ignore\")\n",
    "            b.drop_channels(bads, on_missing=\"ignore\")\n",
    "\n",
    "    # 3) sanity: same sfreq & n_times\n",
    "    if a.info[\"sfreq\"] != b.info[\"sfreq\"]:\n",
    "        raise RuntimeError(f\"Different sfreq: {a.info['sfreq']} vs {b.info['sfreq']}\")\n",
    "    if a.get_data().shape[-1] != b.get_data().shape[-1]:\n",
    "        raise RuntimeError(\"Different n_times between subjects. Check epoching/cropping.\")\n",
    "\n",
    "    # 4) equalize epoch counts IN PLACE\n",
    "    mne.epochs.equalize_epoch_counts([a, b], method=\"truncate\")\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def compute_interbrain_connectivity(epo_a, epo_b, freq_bands, mode=\"ccorr\", epochs_average=True):\n",
    "    \"\"\"\n",
    "    Returns connectivity per band with shape:\n",
    "      result: (n_bands, 2*n_ch, 2*n_ch)\n",
    "      inter-brain slice for band bi: result[bi, 0:n_ch, n_ch:2*n_ch]\n",
    "    \"\"\"\n",
    "    # Ensure aligned\n",
    "    a, b = align_epochs_for_hypyp(epo_a, epo_b, drop_bads=True)\n",
    "    sfreq = a.info[\"sfreq\"]\n",
    "    n_ch = len(a.ch_names)\n",
    "\n",
    "    # HyPyP expects data shaped (2, n_epochs, n_channels, n_times)\n",
    "    data_inter = [a.get_data(), b.get_data()]  # list is fine\n",
    "\n",
    "    # High-level wrapper does TF + connectivity\n",
    "    con = analyses.pair_connectivity(\n",
    "        data_inter, sampling_rate=sfreq, frequencies=freq_bands, mode=mode, epochs_average=epochs_average\n",
    "    )\n",
    "    # con shape: (n_freqs_or_bands, 2*n_ch, 2*n_ch)\n",
    "    # Extract only inter-brain block for each band\n",
    "    C_inter = con[:, 0:n_ch, n_ch : 2 * n_ch]\n",
    "    return C_inter, a, b  # return aligned epochs too for viz\n",
    "\n",
    "\n",
    "def compute_interbrain_connectivity_directional(epo_a, epo_b, freq_bands, measure=\"pdc\"):\n",
    "    \"\"\"\n",
    "    Compute directional inter-brain connectivity using MVAR modeling\n",
    "    \"\"\"\n",
    "    # Ensure aligned\n",
    "    a, b = align_epochs_for_hypyp(epo_a, epo_b, drop_bads=True)\n",
    "    sfreq = a.info[\"sfreq\"]\n",
    "    n_ch = len(a.ch_names)\n",
    "\n",
    "    # Prepare data for MVAR analysis\n",
    "    data_inter = [a.get_data(), b.get_data()]\n",
    "\n",
    "    # Compute analytic signal in frequency bands\n",
    "    complex_signal = analyses.compute_freq_bands(\n",
    "        data_inter, sfreq, freq_bands, filter_length=\"auto\", l_trans_bandwidth=\"auto\", h_trans_bandwidth=\"auto\"\n",
    "    )\n",
    "\n",
    "    # MVAR parameters\n",
    "    mvar_params = {\"mvar_order\": 5, \"fitting_method\": \"default\", \"delta\": 0}\n",
    "\n",
    "    # ICA parameters\n",
    "    ica_params = {\"method\": \"infomax_extended\", \"random_state\": 42}\n",
    "\n",
    "    # Connectivity measure parameters\n",
    "    measure_params = {\"name\": measure, \"n_fft\": 512}  # 'pdc' or 'dtf'\n",
    "\n",
    "    # Compute directional connectivity\n",
    "    conn = analyses.compute_conn_mvar(complex_signal, mvar_params, ica_params, measure_params, check_stability=True)\n",
    "\n",
    "    return conn, a, b\n",
    "\n",
    "\n",
    "# --- 2) Prepare your matched epochs (use your own matched objects) ------------\n",
    "# You already built:\n",
    "#   epo1_cond1_matched, epo1_cond2_matched, epo2_cond1_matched, epo2_cond2_matched\n",
    "# IMPORTANT: your earlier match-by-event-id doesn’t work with fixed-length events\n",
    "# (all event IDs are identical). We rely on equalize_epoch_counts inside aligner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_bands = {\n",
    "    \"Alpha-Low\": [7.5, 11],\n",
    "    \"Alpha-High\": [11.5, 13],\n",
    "    \"Theta\": [4, 7.5],\n",
    "    \"Delta\": [1, 4],\n",
    "    \"Low-Beta\": [13, 20],\n",
    "    \"High-Beta\": [20, 30],\n",
    "    \"Gamma1\": [30, 45],\n",
    "}\n",
    "mode = \"imaginary_coh\"\n",
    "# Condition 1 (e.g., control)\n",
    "C_cond1, epo1_c1_aligned, epo2_c1_aligned = compute_interbrain_connectivity(\n",
    "    epo1_cond1_matched, epo2_cond1_matched, freq_bands, mode=mode, epochs_average=True\n",
    ")\n",
    "# Condition 2 (e.g., limpia)\n",
    "C_cond2, epo1_c2_aligned, epo2_c2_aligned = compute_interbrain_connectivity(\n",
    "    epo1_cond2_matched, epo2_cond2_matched, freq_bands, mode=mode, epochs_average=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_bands = {\n",
    "    \"Alpha-Low\": [7.5, 11],\n",
    "    \"Alpha-High\": [11.5, 13],\n",
    "    \"Theta\": [4, 7.5],\n",
    "    \"Delta\": [1, 4],\n",
    "    \"Low-Beta\": [13, 20],\n",
    "    \"High-Beta\": [20, 30],\n",
    "    \"Gamma1\": [30, 45],\n",
    "}\n",
    "# Use directional connectivity instead\n",
    "measure = \"pdc\"  # or 'dtf'\n",
    "\n",
    "# Condition 1 (e.g., control)\n",
    "C_cond1, epo1_c1_aligned, epo2_c1_aligned = compute_interbrain_connectivity_directional(\n",
    "    epo1_cond1_matched, epo2_cond1_matched, freq_bands, measure=measure\n",
    ")\n",
    "\n",
    "# Condition 2 (e.g., limpia)\n",
    "C_cond2, epo1_c2_aligned, epo2_c2_aligned = compute_interbrain_connectivity_directional(\n",
    "    epo1_cond2_matched, epo2_cond2_matched, freq_bands, measure=measure\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17291677",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"C1 range: {np.min(C1):.3f} to {np.max(C1):.3f}\")\n",
    "print(f\"C1 mean: {np.mean(C1):.3f}, std: {np.std(C1):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa94b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Select a band for visualization ----\n",
    "\n",
    "# C_condX has shape (2 bands, n_ch, n_ch). Pick a band for visualization:\n",
    "band_names = list(freq_bands.keys())\n",
    "band_idx = band_names.index(\"Low-Beta\")  # or 'Alpha-High'\n",
    "C1 = C_cond1[band_idx]\n",
    "C2 = C_cond2[band_idx]\n",
    "\n",
    "# --- 3) Visualize -------------------------------------------------------------\n",
    "# Use the *aligned* epochs returned above\n",
    "thresh = \"auto\"\n",
    "print(\"Condition 1 – 2D:\")\n",
    "viz.viz_2D_topomap_inter(epo1_c1_aligned, epo2_c1_aligned, C1, threshold=thresh, steps=10, lab=True)\n",
    "print(\"Condition 1 – 3D:\")\n",
    "viz.viz_3D_inter(epo1_c1_aligned, epo2_c1_aligned, C1, threshold=thresh, steps=10, lab=False)\n",
    "\n",
    "print(\"Condition 2 – 2D:\")\n",
    "viz.viz_2D_topomap_inter(epo1_c2_aligned, epo2_c2_aligned, C2, threshold=thresh, steps=10, lab=True)\n",
    "print(\"Condition 2 – 3D:\")\n",
    "viz.viz_3D_inter(epo1_c2_aligned, epo2_c2_aligned, C2, threshold=thresh, steps=10, lab=False)\n",
    "\n",
    "# --- 4) (Optional) cluster stats scaffold ------------------------------------\n",
    "# Cluster stats need multiple observations (e.g., multiple dyads or sessions).\n",
    "# With a single dyad, permutation tests are not meaningful.\n",
    "# The snippet below guards against that and shows the expected shapes.\n",
    "\n",
    "do_stats = False  # set True only if you have >= ~10 observations per condition\n",
    "\n",
    "if do_stats:\n",
    "    # Build channel–frequency connectivity (alpha-low only here)\n",
    "    # Flatten n_ch x n_ch to vector per observation if you keep epochs_average=False upstream.\n",
    "    # With epochs_average=True, you already have one matrix per dyad/condition.\n",
    "    # Example uses spatial+frequency connectivity helper:\n",
    "    from hypyp.stats import (\n",
    "        con_matrix,\n",
    "        indices_connectivity_interbrain,\n",
    "        metaconn_matrix_2brains,\n",
    "    )\n",
    "\n",
    "    # Create a merged Epochs to get inter-brain indices for metaconn (any aligned pair works)\n",
    "    merged = mne.concatenate_epochs([epo1_c1_aligned.copy(), epo2_c1_aligned.copy()])\n",
    "    inter_pairs = analyses.indices_connectivity_interbrain(merged)\n",
    "\n",
    "    alpha_freqs = np.arange(8, 13)\n",
    "    conn = stats.con_matrix(epo1_c1_aligned, freqs_mean=alpha_freqs)\n",
    "    meta = stats.metaconn_matrix_2brains(inter_pairs, conn.ch_con, freqs_mean=alpha_freqs)\n",
    "\n",
    "    # data_for_stats must be [array(shape=(n_obs, n_features)), array(...)]\n",
    "    # You would stack *many* dyads/session entries here.\n",
    "    # stats.statscondCluster(data, freqs_mean=alpha_freqs, ch_con_freq=meta.metaconn_freq,\n",
    "    #                        tail=0, n_permutations=5000, alpha=0.05)\n",
    "    pass  # You would stack *many* dyads/session entries here.\n",
    "    # stats.statscondCluster(data, freqs_mean=alpha_freqs, ch_con_freq=meta.metaconn_freq,\n",
    "    #                        tail=0, n_permutations=5000, alpha=0.05)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee860bf",
   "metadata": {},
   "source": [
    "## Directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b347251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce071e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3086721e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
